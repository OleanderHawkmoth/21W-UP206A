{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tweepy for Twitter Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://docs.tweepy.org/en/v3.9.0/getting_started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# the regulars\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import osmnx as ox\n",
    "\n",
    "# to get tweets\n",
    "import tweepy as tw\n",
    "\n",
    "# for sentiment analysis\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "# word clouds\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter with tweepy\n",
    "\n",
    "In order to use twitter's api, you will need a developer's account. You will then have the ability to generate the tokens needed to use their API.\n",
    "\n",
    "- http://docs.tweepy.org/en/latest/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your twitter keys/secrets/tokens\n",
    "consumer_key= ''\n",
    "consumer_secret= ''\n",
    "access_token= ''\n",
    "access_token_secret= ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authenticate thyself with twitter\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets by username\n",
    "- http://docs.tweepy.org/en/latest/api.html#API.user_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of query method using parameters\n",
    "tweets = tw.Cursor(api.user_timeline, id='BillGates', tweet_mode='extended').items(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, tweet in enumerate(tweets):\n",
    "    print(index, tweet.full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets by keyword\n",
    "\n",
    "* search parameters: http://docs.tweepy.org/en/latest/api.html#search-methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search query\n",
    "q = 'covid'\n",
    "\n",
    "# filter out retweets (optional of course)\n",
    "q = q + \" -filter:retweets\"\n",
    "\n",
    "# how many?\n",
    "max_tweets = 500\n",
    " \n",
    "# Creation of query method using parameters\n",
    "tweets = tw.Cursor(api.search,q=q, tweet_mode='extended').items(max_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, tweet in enumerate(tweets):\n",
    "    print(index, tweet.full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets by keyword and place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search,q=q,geocode='34.068921,-118.4473751,50km', tweet_mode='extended').items(max_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, tweet in enumerate(tweets):\n",
    "    print(index, tweet.full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The tweet object\n",
    "\n",
    "For reasons that I am unable to verify, the tweet object that is returned by the `tw.Cursor` function can only fun a single loop operation before it mysteriously disappears (if anybody can figure this one out, let me know!). For that reason, run the search again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for covid tweets in LA\n",
    "tweets = tw.Cursor(api.search,q=q,geocode='34.068921,-118.4473751,50km', tweet_mode='extended').items(max_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweet object is in *json* format. We can convert it into a dataframe for easier access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = [tweet._json for tweet in tweets]\n",
    "df = pd.json_normalize(json_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of columns! Twitter saves a ton of metadata for each tweet... Let's clean this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['created_at','full_text','user.screen_name','user.profile_image_url_https']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['created_at','text','screen_name','profile_image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, let's convert the profile image url's into actual images. This is somewhat of a hack, and only works with the applied code below (ie, it's not baked into the dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, HTML\n",
    "\n",
    "# df = pd.DataFrame(['./image01.png', './image02.png'], columns = ['Image'])\n",
    "\n",
    "def path_to_image_html(path):\n",
    "    return '<img src=\"'+ path + '\"/>'\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "HTML(df.to_html(escape=False ,formatters=dict(profile_image=path_to_image_html)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Now it's your turn! Get creative and create your own twitter search queries on matters that interest you.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud\n",
    "Word clouds are great to visually display word clusters. The algorithms are simple. More word frequency, larger font size, less frequent words, smaller fonts sizes.\n",
    "\n",
    "We will use the [word_cloud library](https://github.com/amueller/word_cloud).\n",
    "\n",
    "First though, we need to clean up the tweets. Tweets are notorious for having strange characters and emoji's!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean tweets using regular expressions\n",
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of cleaning a tweet\n",
    "tweet = df.sample().text.values[0]\n",
    "print(tweet)\n",
    "clean_tweet(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column for the clean text\n",
    "df['clean_text'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop and add the cleaned up text to the new column\n",
    "for i, row in df.iterrows():\n",
    "    clean = clean_tweet(row.text)\n",
    "    df.at[i,'clean_text'] = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)[['text','clean_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Every tweet has been cleaned up. In order to create a word cloud, we need to create a single variable that has every word in every tweet from our twitter dataframe. We then feed that to the world cloud factory that will generate the word cloud for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now put every word into a single variable\n",
    "all_text = ' '.join(df['clean_text'])\n",
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the word cloud\n",
    "wordcloud = WordCloud(width=1200, \n",
    "                      height=800,\n",
    "                      background_color=\"white\").generate(all_text)\n",
    "\n",
    "# Display the WordCloud                    \n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "For sentiment analysis, we will use the [textblob](https://textblob.readthedocs.io/en/dev/) python library.\n",
    "\n",
    "The sentiment property returns a tuple of the form `Sentiment(polarity, subjectivity)`. The polarity score ranges from -1 (most negative) to +1 (most positive). The subjectivity ranges from 0 to 1, where 0.0 is very objective and 1.0 is very subjective.\n",
    "\n",
    "Let's test this out on a random tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random tweet\n",
    "tweet = df.sample().clean_text.values[0]\n",
    "print(tweet)\n",
    "\n",
    "# analyze the tweet\n",
    "a = TextBlob(tweet)\n",
    "\n",
    "# results\n",
    "a.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an new (empty) column for polarity\n",
    "df['polarity']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through every row and add the polarity value in our new column\n",
    "for i, row in df.iterrows():\n",
    "    a = TextBlob(row.text)\n",
    "    df.at[i,'polarity'] = a.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['clean_text','polarity']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quantify the results. Tweets are either positive, neutral, or negative, so let's give them categorical values.\n",
    "\n",
    "Numpy has a convenient function `.select` that allows you to generate a categorical ranking based on conditional arguments on a given column. In other words, we can assign tweets to be \"positive\" or \"negative\" based on their polarity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of our conditions\n",
    "conditions = [\n",
    "    (df['polarity'] < 0), # negative\n",
    "    (df['polarity'] == 0), # neutral\n",
    "    (df['polarity'] > 0) # positive\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = [\n",
    "    'negative', \n",
    "    'neutral', \n",
    "    'positive'\n",
    "    ]\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df['sentiment'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display updated DataFrame\n",
    "df.sample(5)[['clean_text','polarity','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(df, \n",
    "             names='sentiment',\n",
    "             width=600,\n",
    "             title='Sentiment analysis for '+q,\n",
    "             color='sentiment',\n",
    "             color_discrete_map={'positive':'#91cf60','neutral':'#ffffbf','negative':'#d73027'}\n",
    "            )\n",
    "fig.update_traces(textinfo='value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 50\n",
    "plt.figure(figsize=(10,6))\n",
    "n, bins, patches = plt.hist(df.polarity, num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.xlabel('Polarity')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of polarity')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's make a function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tweets(q,place,distance='50km',count=500):\n",
    "    \n",
    "    #\n",
    "    # geocode the place to get coordinates\n",
    "    #\n",
    "    \n",
    "    g = ox.geocoder.geocode(place)\n",
    "    \n",
    "    # concatenate the results\n",
    "    geocode = '\"'+str(g[0])+','+str(g[1])+','+distance+'\"'\n",
    "    \n",
    "    #\n",
    "    # grab the tweets\n",
    "    #\n",
    "    \n",
    "    tweets = tw.Cursor(api.search,\n",
    "                       q=q+' -filter:retweets', # no retweets\n",
    "                       geocode=geocode, \n",
    "                       tweet_mode='extended').items(count)\n",
    "    #\n",
    "    # create a dataframe\n",
    "    #\n",
    "    \n",
    "    json_data = [tweet._json for tweet in tweets]\n",
    "    df = pd.json_normalize(json_data)\n",
    "\n",
    "    # clean it up\n",
    "    df = df[['created_at','full_text']]\n",
    "\n",
    "    # clean the text\n",
    "    df['clean_text'] = ''\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        clean = clean_tweet(row.full_text)\n",
    "        df.at[i,'clean_text'] = clean\n",
    "\n",
    "    #\n",
    "    # word cloud\n",
    "    #\n",
    "    \n",
    "    all_text = ' '.join(df['clean_text'])\n",
    "    \n",
    "    # create the word cloud\n",
    "    wordcloud = WordCloud(width=1200, \n",
    "                          height=800,\n",
    "                          background_color=\"white\").generate(all_text)\n",
    "\n",
    "    # Display the WordCloud                    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    #\n",
    "    # sentiment analysis\n",
    "    #\n",
    "    \n",
    "    df['polarity']=''\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        a = TextBlob(row.full_text)\n",
    "        df.at[i,'polarity'] = a.polarity\n",
    "    \n",
    "    # create a list of our conditions\n",
    "    \n",
    "    conditions = [\n",
    "        (df['polarity'] < 0), # negative\n",
    "        (df['polarity'] == 0), # neutral\n",
    "        (df['polarity'] > 0) # positive\n",
    "        ]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = [\n",
    "        'negative', \n",
    "        'neutral', \n",
    "        'positive'\n",
    "        ]\n",
    "\n",
    "    # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    df['sentiment'] = np.select(conditions, values)\n",
    "\n",
    "    fig = px.pie(df, \n",
    "                 names='sentiment',\n",
    "                 width=600,\n",
    "                 title='Sentiment analysis for '+q,\n",
    "                 color='sentiment',\n",
    "                 color_discrete_map={'positive':'#91cf60','neutral':'#ffffbf','negative':'#d73027'}\n",
    "                )\n",
    "    fig.update_traces(textinfo='value')\n",
    "    fig.show()\n",
    "    \n",
    "    num_bins = 50\n",
    "    plt.figure(figsize=(10,6))\n",
    "    n, bins, patches = plt.hist(df.polarity, num_bins, facecolor='blue', alpha=0.5)\n",
    "    plt.xlabel('Polarity')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Average polarity: '+str(df.polarity.mean()))\n",
    "    plt.show();\n",
    "    return df.sample(5)[['clean_text','polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_tweets(q='trump',place='90095')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_tweets(q='biden',place='90095')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tweets_user(u,count=500):\n",
    "    \n",
    "    #\n",
    "    # grab the tweets\n",
    "    #\n",
    "    tweets = tw.Cursor(api.user_timeline, \n",
    "                       id=u, \n",
    "                       tweet_mode='extended').items(count)\n",
    "    \n",
    "    #\n",
    "    # create a dataframe\n",
    "    #\n",
    "    \n",
    "    json_data = [tweet._json for tweet in tweets]\n",
    "    df = pd.json_normalize(json_data)\n",
    "\n",
    "    # clean it up\n",
    "    df = df[['created_at','full_text']]\n",
    "\n",
    "    # clean the text\n",
    "    df['clean_text'] = ''\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        clean = clean_tweet(row.full_text)\n",
    "        df.at[i,'clean_text'] = clean\n",
    "\n",
    "    #\n",
    "    # word cloud\n",
    "    #\n",
    "    \n",
    "    all_text = ' '.join(df['clean_text'])\n",
    "    \n",
    "    # create the word cloud\n",
    "    wordcloud = WordCloud(width=1200, \n",
    "                          height=800,\n",
    "                          background_color=\"white\").generate(all_text)\n",
    "\n",
    "    # Display the WordCloud                    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    #\n",
    "    # sentiment analysis\n",
    "    #\n",
    "    \n",
    "    df['polarity']=''\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        a = TextBlob(row.full_text)\n",
    "        df.at[i,'polarity'] = a.polarity\n",
    "    \n",
    "    # create a list of our conditions\n",
    "    \n",
    "    conditions = [\n",
    "        (df['polarity'] < 0), # negative\n",
    "        (df['polarity'] == 0), # neutral\n",
    "        (df['polarity'] > 0) # positive\n",
    "        ]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = [\n",
    "        'negative', \n",
    "        'neutral', \n",
    "        'positive'\n",
    "        ]\n",
    "\n",
    "    # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    df['sentiment'] = np.select(conditions, values)\n",
    "\n",
    "    fig = px.pie(df, \n",
    "                 names='sentiment',\n",
    "                 width=600,\n",
    "                 title='Sentiment analysis for '+q,\n",
    "                 color='sentiment',\n",
    "                 color_discrete_map={'positive':'#91cf60','neutral':'#ffffbf','negative':'#d73027'}\n",
    "                )\n",
    "    fig.update_traces(textinfo='value')\n",
    "    fig.show()\n",
    "    \n",
    "    num_bins = 50\n",
    "    plt.figure(figsize=(10,6))\n",
    "    n, bins, patches = plt.hist(df.polarity, num_bins, facecolor='blue', alpha=0.5)\n",
    "    plt.xlabel('Polarity')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Average polarity: '+str(df.polarity.mean()))\n",
    "    plt.show();\n",
    "    return df.sample(5)[['clean_text','polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_tweets_user(u='realDonaldTrump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_tweets_user(u='JoeBiden')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
